#! https://zhuanlan.zhihu.com/p/687939793
# NVIDIA GB200 提供万亿参数 LLM 训练和实时推理

![](https://developer-blogs.nvidia.com/wp-content/uploads/2024/03/GB200-NVL72-Key-Visual.png)


万亿参数模型有什么好处？ 我们了解当今的许多用例，并且由于有望增加以下方面的容量，人们的兴趣与日俱增：

* 自然语言处理任务，如翻译、问答、抽象和流畅性。
* 掌握更长期的背景和对话能力。
* 结合语言、视觉和语音的多模态应用。
* 创意应用程序，例如讲故事、诗歌生成和代码生成。
* 科学应用，例如蛋白质折叠预测和药物发现。
* 个性化，能够形成一致的个性并记住用户上下文。

好处是巨大的，但训练和部署大型模型可能会耗费大量计算资源和资源。 计算高效、经济有效且节能的系统，旨在提供实时推理，对于广泛部署至关重要。 新型 NVIDIA GB200 NVL72 就是一款能够胜任这项任务的系统。

为了说明这一点，让我们考虑专家混合 (MoE) 模型。 这些模型有助于在多个专家之间分配计算负载，并使用模型并行性和管道并行性在数千个 GPU 上进行训练。 使系统更加高效。

然而，新水平的并行计算、高速内存和高性能通信可以使 GPU 集群轻松应对技术挑战。 NVIDIA GB200 NVL72 机架级架构实现了这一目标，我们将在下面的文章中详细介绍。


## 百亿亿次人工智能超级计算机的机架级设计
[GB200 NVL72](https://www.nvidia.com/en-us/data-center/gb200-nvl72/) 的核心是 NVIDIA GB200 Grace Blackwell 超级芯片。 它通过 NVLink 芯片到芯片 (C2C) 接口连接两个高性能 NVIDIA Blackwell Tensor Core GPU 和 NVIDIA Grace CPU，可提供 900 GB/s 的双向带宽。 借助 NVLink-C2C，应用程序可以对统一内存空间进行一致访问。 这简化了编程并支持万亿参数 LLM、多模式任务的变压器模型、大规模模拟的模型以及 3D 数据的生成模型的更大内存需求。

GB200 计算托盘基于全新 NVIDIA MGX 设计。 它包含两个 Grace CPU 和四个 Blackwell GPU。 GB200 具有用于液体冷却的冷板和连接、用于高速网络的 PCIe gen 6 支持以及用于 NVLink 电缆盒的 NVLink 连接器。 GB200 计算托盘可提供 80 petaflops 的 AI 性能和 1.7 TB 的快速内存。

![](https://developer-blogs.nvidia.com/wp-content/uploads/2024/03/gb200-compute-tray.png)


最大的问题需要足够数量的突破性 Blackwell GPU 才能高效地并行工作，因此它们必须以高带宽和低延迟进行通信，并保持持续忙碌。

GB200 NVL72 机架规模系统使用带有 9 个 NVLink 交换机托盘的 NVIDIA NVLink 交换机系统以及互连 GPU 和交换机的电缆盒，可提高 18 个计算节点的并行模型效率。

## NVIDIA GB200 NVL36 和 NVL72
GB200 支持 NVLink 域中的 36 个和 72 个 GPU。 每个机架托管 18 个基于 MGX 参考设计和 NVLink 交换机系统的计算节点。 它采用 GB200 NVL36 配置，一个机架中有 36 个 GPU，还有 18 个单个 GB200 计算节点。 GB200 NVL72 在一个机架中配置了 72 个 GPU 和 18 个双 GB200 计算节点，或者在两个机架中配置了 72 个 GPU，并具有 18 个单 GB200 计算节点。

GB200 NVL72 使用铜电缆盒密集地封装和互连 GPU，以简化操作。 它还采用液体冷却系统设计，使成本和能耗降低 25 倍。
![](https://developer-blogs.nvidia.com/wp-content/uploads/2024/03/nvlink-switch-system.png)

## 第五代 NVLink 和 NVLink 开关系统
NVIDIA GB200 NVL72 引入了第五代 NVLink，可在单个 NVLink 域中连接多达 576 个 GPU，总带宽超过 1 PB/s，快速内存可达 240 TB。 每个 NVLink 交换机托盘提供 144 个 100 GB 的 NVLink 端口，因此这 9 个交换机完全连接 72 个 Blackwell GPU 上每一个的 18 个 NVLink 端口。

每个 GPU 革命性的 1.8 TB/s 双向吞吐量是 PCIe Gen5 带宽的 14 倍以上，为当今最复杂的大型模型提供无缝高速通信。

![](https://developer-blogs.nvidia.com/wp-content/uploads/2024/03/nvlink-switch-tray.png)

## NVLink历经数代
NVIDIA 业界领先的高速低功耗 SerDes 创新推动了 GPU 到 GPU 通信的进步，首先是引入 NVLink 以加速高速多 GPU 通信。 NVLink GPU 到 GPU 的带宽为 1.8 TB/s，是 PCIe 带宽的 14 倍。 第五代 NVLink 于 2014 年推出，速度为 160 GB/s，比第一代快 12 倍。NVLink GPU 到 GPU 通信在扩展 AI 和 HPC 中的多 GPU 性能方面发挥了重要作用。

GPU 带宽的进步加上 NVLink 域大小的指数级扩展，自 2014 年以来 NVLink 域的总带宽增加了 900 倍，对于 576 个 Blackwell GPU NVLink 域而言，带宽达到了 1 PB/s。


## 使用案例和性能结果
GB200 NVL72的计算和通信能力是前所未有的，给人工智能和高性能计算带来了实际可行的巨大挑战。

### 人工智能训练
GB200 包括更快的第二代变压器引擎，具有 FP8 精度。 与相同数量的 NVIDIA H100 GPU 相比，它通过 32k GB200 NVL72 为 GPT-MoE-1.8T 等大型语言模型提供了 4 倍更快的训练性能。

### 人工智能推理
GB200 引入了尖端功能和第二代变压器引擎，可加速 LLM 推理工作负载。 与上一代 H100 相比，它为 1.8T 参数 GPT-MoE 等资源密集型应用程序提供了 30 倍的加速。 这一进步是通过新一代 Tensor Core 实现的，它引入了 FP4 精度以及第五代 NVLink 带来的许多优势

![](https://developer-blogs.nvidia.com/wp-content/uploads/2024/03/blackwell-charts-gtc24_gb-gpt-moe-model@2x.png)


通过 8 路 NVLink 和 InfiniBand 扩展的 64 个 NVIDIA Hopper GPU 与使用 GPT-MoE-1.8T 的 GB200 NVL72 中的 32 个 Blackwell GPU 相比，速度提升了 30 倍。

## 数据处理
大数据分析帮助组织释放洞察力并做出更明智的决策。 组织不断大规模生成数据，并依靠各种压缩技术来缓解瓶颈并节省存储成本。 为了在 GPU 上高效处理这些数据集，Blackwell 架构引入了硬件解压缩引擎，该引擎可以大规模本地解压缩压缩数据并加速端到端的分析管道。 解压引擎原生支持解压使用 LZ4、Deflate 和 Snappy 压缩格式压缩的数据。

解压缩引擎加速内存绑定的内核操作。 它提供高达 800 GB/s 的性能，使 Grace Blackwell 在查询基准测试中的执行速度比 CPU (Sapphire Rapids) 快 18 倍，比 NVIDIA H100 Tensor Core GPU 快 6 倍。

凭借高达 8 TB/s 的高内存带宽和 Grace CPU 高速 NVlink 芯片到芯片 (C2C)，该引擎加快了数据库查询的整个过程。 这使得数据分析和数据科学用例的性能达到一流。 这使组织能够快速获得见解，同时降低成本。

![](https://developer-blogs.nvidia.com/wp-content/uploads/2024/03/hopper-grace-database-join-query.png)

## 基于物理的模拟
基于物理的模拟仍然是产品设计和开发的支柱。 从飞机和火车到桥梁、硅芯片，甚至药品，通过模拟测试和改进产品可以节省数十亿美元。

专用集成电路几乎完全在 CPU 上通过漫长而复杂的工作流程进行设计，包括用于识别电压和电流的模拟分析。 Cadence SpectreX 模拟器是求解器的一个示例。 下图显示 SpectreX 在 GB200 上的运行速度比在 x86 CPU 上快 13 倍。

![](https://developer-blogs.nvidia.com/wp-content/uploads/2024/03/hopper-grace-cfd-simulation.png)

过去两年，业界越来越多地将 GPU 加速的计算流体动力学 (CFD) 作为关键工具。 工程师和设备设计师使用它来研究和预测其设计的行为。 Cadence Fidelity 是一款大型涡流模拟器 (LES)，在 GB200 上运行模拟的速度比 x86 CPU 快 22 倍。

![](https://developer-blogs.nvidia.com/wp-content/uploads/2024/03/hopper-grace-cfd-simulation-speedup.png)

我们期待探索 Cadence Fidelity 在 GB200 NVL72 上的可能性。 凭借并行可扩展性和每个机架 30 TB 的内存，我们的目标是捕获以前从未捕获过的流细节。

## 总结
回顾一下，我们回顾了 GB200 NVL72 机架规模设计，特别了解了其在单个 NVIDIA NVLink 域上连接 72 个 Blackwell GPU 的独特功能。 这减少了在传统网络上扩展时所经历的通信开销。 因此，可以对 1.8T 参数 MoE LLM 进行实时推理，并且该模型的训练速度提高了 4 倍。

72 个 NVLink 连接的 Blackwell GPU 和 30 TB 统一内存在 130 TB/s 计算结构上运行，在单个机架中创建了 exaFLOP AI 超级计算机。 那就是 NVIDIA GB200 NVL72。

































