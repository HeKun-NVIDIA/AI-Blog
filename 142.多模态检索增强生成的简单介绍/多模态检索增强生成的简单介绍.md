# 多模态检索增强生成的简单介绍
![](https://developer-blogs.nvidia.com/wp-content/uploads/2024/03/multi-modal-rag-featured.jpg)


如果[检索增强生成](https://www.nvidia.com/en-us/glossary/retrieval-augmented-generation/) (RAG) 应用程序可以处理多种数据类型（表格、图形、图表和图表）而不仅仅是文本，那么它的实用性就会呈指数级增长。 这需要一个能够通过连贯地解释文本、视觉和其他形式的信息来理解并生成响应的框架。

在这篇文章中，我们讨论了应对多种模式和方法来构建多模式 RAG 管道的挑战。 为了使讨论简洁，我们只关注两种模式：图像和文本。

## 为什么多模态很难？
企业（非结构化）数据通常分布在多种模式中，无论是充满高分辨率图像的文件夹还是包含文本表格、图表、图表等的混合的 PDF。

在处理此类模态传播时，需要考虑两个要点：每种模态都有其自身的挑战以及如何管理跨模态的信息？


## 每种模式都有其自身的挑战
例如，考虑图像（如下图所示）。 对于左侧的图像，重点更多地放在一般图像上，而不是微小的细节上。 注意力只集中在池塘、海洋、树木和沙子等几个关键点上。


![](https://developer-blogs.nvidia.com/wp-content/uploads/2024/03/increasing-complexity-of-images.png)


报告和文档可能包含信息密集的图像，例如图表和图表，其中有许多兴趣点和可以从图像中得出的其他上下文。 无论您构建什么管道，都必须捕获并解决这些细微差别，以有效地嵌入信息。

### 您如何跨模式管理信息？
另一个重要方面是跨不同模式表示信息。 例如，如果您正在处理文档，则必须确保图表的语义表示与讨论同一图表的文本的语义表示一致。

## 多模态检索方法
了解了关键挑战后，以下是构建 RAG 管道以应对这些挑战的具体细节。

构建多模式 RAG 流程有几种主要方法：

* 将所有模态嵌入到同一向量空间中
* 将所有模式归结为一种主要模式
* 对于不同的方式有单独的商店
* 为了使讨论简洁，我们只讨论图像和文本输入。


### 将所有模态嵌入到同一向量空间中
对于图像和文本，您可以使用 CLIP 等模型在同一向量空间中对文本和图像进行编码。 这使得您可以在很大程度上使用相同的纯文本 RAG 基础设施并更换嵌入模型以适应另一种模式。 对于生成过程，您可以将所有问答的大语言模型 (LLM) 替换为多模式 LLM (MLLM)。

这种方法简化了管道，因为通用检索管道中所需的唯一更改是交换嵌入模型。

在这种情况下，需要权衡的是获得一个模型，该模型可以有效地嵌入不同类型的图像和文本，并且还可以捕获所有复杂的信息，例如图像中的文本和复杂的表格。

### 将所有模式归结为一种主要模式
另一种选择是根据应用程序的重点选择主要模式，并将所有其他模式置于主要模式中。

例如，假设您的应用程序主要围绕 PDF 上基于文本的问答。 在这种情况下，您可以正常处理文本，但对于图像，您可以在预处理步骤中创建文本描述和元数据。 您还可以存储图像以供以后使用。

在推理过程中，检索主要根据图像的文本描述和元数据进行，并根据检索的图像类型，通过 LLM 和 MLLM 的混合生成答案。

这里的主要好处是，从信息丰富的图像生成的元数据对于回答客观问题非常有帮助。 这也解决了调整嵌入图像的新模型以及构建重新排序器以对不同模式的结果进行排序的需要。 主要缺点是预处理成本和丢失图像的一些细微差别。

### 对于不同的方式有单独的备用
排名重新排名是另一种方法，您可以为不同的模态提供单独的存储，查询它们以检索前 N 个块，然后让专用的多模态重新排名器提供最相关的块。

这种方法简化了建模过程，因此您不必调整一个模型即可使用多种模式。 然而，它以重新排序器的形式增加了复杂性，以排列现在的 top-M*N 块（每个块来自 M 种模式）。

## 多模式生成模型
LLM旨在理解、解释和生成基于文本的信息。 经过大量文本数据的训练，LLM可以执行一系列自然语言处理任务，例如文本生成、摘要、问答等。

MLLM 可以感知的不仅仅是文本数据。 MLLM 可以处理图像、音频和视频等模式，这通常是现实世界数据的组成方式。 他们将这些不同的数据类型结合起来，对信息进行更全面的解释，从而提高预测的准确性和稳健性。

这些模型可以执行广泛的任务：

* 视觉语言理解和生成
* 多模态对话
* 图像字幕
* 视觉问答（VQA）

这些都是 RAG 系统在处理多种模式时可以受益的任务。 要更深入地了解 MLLM 如何处理图像和文本，需要了解这些模型的构建方式。

MLLM 的流行子类型之一是 Pix2Struct，这是一种预训练的图像到文本模型，可以通过其新颖的预训练策略对视觉输入进行语义理解。 顾名思义，这些模型生成从图像中提取的结构化信息。 例如，Pix2Struct模型可以从图表中提取关键信息并以文本形式表达。

了解了这一点后，您可以按照以下步骤构建 RAG 流程。

## 构建多模式 RAG 流程
为了展示如何处理不同形式的数据，我们将引导您完成索引多个技术帖子的应用程序，例如使用 NVIDIA H100 GPU 打破 MLPerf 训练记录。 这篇文章包含复杂的图像，这些图像是带有富文本、表格数据，当然还有段落的图表和图形。

以下是开始处理数据和构建 RAG 管道之前所需的模型和工具：

* MLLM：用于图像字幕和 VQA。
* LLM：一般推理和问题回答。
* 嵌入模型：将数据编码为向量。
* 矢量数据库：存储编码矢量以供检索。

### 解释多模态数据并创建矢量数据库

构建 RAG 应用程序的第一步是预处理数据并将其作为向量存储在向量存储中，以便您可以根据查询检索相关向量。

对于数据中存在的图像，下面是一个通用的 RAG 预处理工作流程（下图所示）。
![](https://developer-blogs.nvidia.com/wp-content/uploads/2024/03/rag-preprocessing-for-images.png)

该帖子包含几个条形图，如下图所示。要解释这些条形图，请使用 Google 的 DePlot，这是一种视觉语言模型，与LLM结合使用时能够理解图表和绘图。 该模型可在 NGC 上找到。

有关在 RAG 应用程序中使用 DePlot API 的更多信息，请参阅[使用优化的 DePlot 模型查询图](https://developer.nvidia.com/blog/query-graphs-with-optimized-deplot-model/)。

![](https://developer-blogs.nvidia.com/wp-content/uploads/2024/03/example-bar-chart-1-768x377.png)

此示例重点介绍图表和绘图。 其他文档可能包含可能需要模型定制来处理专门图像的图像，例如医学图像或示意图。 这取决于用例，但您有多种选择来解决图像中的这种差异：调整一个 MLLM 来处理所有类型的图像，或者为不同类型的图像构建模型集合。

为了使解释简单，这是一个包含两个类别的简单集成案例：

* 使用 [DePlot](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/ai-foundation/models/deplot) 处理带有图形的图像
* 其他要使用 MLLM（如 [KOSMOS2](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/ai-foundation/models/kosmos-2)）处理的图像

在这篇文章中，我们扩展了预处理管道，以更深入地处理管道中的每种模式，利用自定义文本拆分器、自定义 MLLM 和 LLM 来创建 VectorDB（下图）。

![](https://developer-blogs.nvidia.com/wp-content/uploads/2024/03/rag-preprocessing-workflow-1.png)

以下是预处理工作流程中的一些关键步骤：

* 分离图像和文本
* 根据图像类型使用 MLLM 对图像进行分类
* 在 PDF 中嵌入文本
### 分离图像和文本
目标是将图像转化为文本形式。 首先提取和清理数据以分离图像和文本。 然后，您可以着手处理这两种模式，最终将它们存储在向量存储中。

### 根据图像类型使用 MLLM 对图像进行分类
MLLM 生成的图像描述可用于将图像分类，无论它们是否是图形。 根据分类，对包含图形的图像使用 DePlot 来生成线性化的表格文本。 该文本在语义上与常规文本不同，这给在推理过程中执行搜索时检索相关信息带来了挑战。

我们建议使用线性化文本的摘要作为块存储在向量存储中，并将自定义 MLLM 的输出作为元数据，您可以在推理期间使用。

### 在 PDF 中嵌入文本
您可以根据正在使用的数据探索各种文本分割技术，以实现最佳 RAG 性能。 为简单起见，将每个段落存储为一个块。

## 与您的矢量数据库对话
通过此管道，您可以成功捕获 PDF 中存在的所有多模式信息。 以下是当用户提出问题时 RAG 管道的工作方式。

当用户向系统提出问题时，简单的 RAG 管道会将问题转换为嵌入，并执行语义搜索以检索一些相关的信息块。 考虑到检索到的块也来自图像，在将所有块发送到 LLM 以生成最终响应之前，请执行一些额外的步骤。

下图 显示了如何使用从图像和文本中检索为块的信息来处理用户查询并进行回答的参考流程。

![](https://developer-blogs.nvidia.com/wp-content/uploads/2024/03/rag-inference-workflow.png)

下面是一个示例问题，提示支持多模式 RAG 的机器人可以访问感兴趣的 PDF，“具有 3D U-Net 的 NVIDIA A100 和 NVIDIA H100(v2.1) 之间的性能差异是什么？”

该管道成功检索了相关图形图像，并准确地解释了它，在 3D U-Net 基准测试中，NVIDIA H100 (v2.1) 每个加速器的相对性能比 NVIDIA A100 高出 80%。

![](https://developer-blogs.nvidia.com/wp-content/uploads/2024/03/schrodinger-answer.png)

以下是执行搜索并检索前五个相关块后处理问题所涉及的一些关键步骤：

* 如果块是从图像中提取的，MLLM 会将图像和用户问题一起作为输入来生成答案。 这只不过是一个 VQA 任务。 然后，生成的答案将用作LLM做出响应的最终上下文。
* 如果从图表或图中提取块，请调用存储为元数据的线性化表，并将文本作为上下文附加到 LLM。
* 最后，来自纯文本的块按原样使用。

所有这些块以及用户问题现在都已准备好供LLM生成最终答案。 根据图 6 中列出的来源，机器人参考了显示不同基准上的相对性能的图表，以生成准确的最终响应。

## 扩展 RAG 管道
这篇文章涉及使用跨多种模式的数据来回答简单的基于文本的问题的场景。 为了进一步发展多模态 RAG 技术并扩展其功能，我们建议进行以下研究领域。

### 解决包含不同模式的用户问题
考虑一个由包含图表和问题列表的图像组成的用户问题，需要对管道进行哪些更改才能适应这种类型的多模式请求？

### 多模式反应
基于文本的答案提供了代表其他模式的引文，如图 6 所示。但是，书面解释可能并不总是用户查询的最佳结果类型。 例如，多模式响应可以进一步扩展以根据请求生成图像，例如堆叠条形图。

### 多式联运代理人
解决复杂的问题或任务超出了简单的检索的范围。 这需要规划、专用工具和摄取引擎。 有关更多信息，请参阅 [LLM 代理简介](https://developer.nvidia.com/blog/introduction-to-llm-agents/)。


## 概括
由于多模态模型的进步以及对 RAG 驱动的工具和服务的需求增加，生成式 AI 应用中的未来多模态功能还有很大的改进和探索空间。

能够将多模式功能集成到其核心运营和技术工具中的企业能够更好地扩展其人工智能服务和产品，以适应尚未列出的用例。

获得在 GitHub 中[实施多模式 RAG 工作流程](https://github.com/NVIDIA/GenerativeAIExamples/tree/main/experimental/multimodal_assistant)的实践经验。






























