# 为自动驾驶设计最佳 AI 推理流程

![](https://developer-blogs.nvidia.com/wp-content/uploads/2022/11/image1-2.jpg)

自动驾驶汽车必须能够快速准确地检测物体，以确保其驾驶员和道路上其他驾驶员的安全。由于在自动驾驶 (AD) 和视觉检查用例中需要实时处理，因此将具有预处理和后处理逻辑的多个 AI 模型组合在一个管道中，并用于机器学习 (ML) 推理。

管道的每个步骤都需要加速以确保低延迟工作流。延迟是获得推理响应所需的时间。更快地处理 AD 数据将有助于更有效地分析和使用信息，从而创造更安全的驾驶环境。任何一个方面的延迟都会减慢整个管道。

为了实现低延迟推理工作流程，电动汽车制造商 NIO 将 NVIDIA Triton 推理服务器集成到他们的 AD 推理管道中。 NVIDIA Triton 推理服务器是一种开源多框架推理服务软件。

这篇文章解释了 NIO 如何在 GPU 上使用 NVIDIA Triton 协调其图像预处理和后处理以及 AI 模型的管道。它还展示了 NIO 如何减少网络传输以成功加速其针对 AD 用例的 AI 推理工作流程。

## 更快的 AI 推理以实现实时响应
NIO 设计、开发、联合制造和销售高端智能电动汽车，推动自动驾驶、数字技术、电动动力总成和电池等下一代技术的创新。 蔚来自动驾驶开发平台（NADP）是专注于蔚来核心自动驾驶服务的研发平台。

NIO 选择 NVIDIA Triton 推理服务器是出于几个关键的技术和运营原因，包括：

* NVIDIA Triton 支持基于 DAG 的众多模型编排，以及预处理或后处理模块
* NVIDIA Triton 的云原生部署以轻量级方式支持多 GPU、多节点扩展
* 高质量的文档和学习资源有助于轻松迁移到 NVIDIA Triton
* NVIDIA Triton 的稳定性和强大的功能是 AD 用例所必需的

## NIO 的自动驾驶 AI 推理工作流程
数以百计的人工智能模型被用来从自动驾驶汽车中挖掘数据。 在像自动驾驶这样的用例中，推理工作流由多个 AI 模型组成，预处理和后处理逻辑在管道中缝合在一起。

NIO 将管道的预处理和后处理从运行在 CPU 上的客户端转移到运行在 GPU 上的 NVIDIA Triton。 NVIDIA Triton 的业务逻辑脚本 (BLS) 功能用于编排管道以最佳方式运行以供 AD 使用。

通过将预处理从 CPU 转移到 GPU 并利用高效的流水线编排，NIO 在一些核心流水线中实现了 6 倍的延迟减少，将整体吞吐量提高了 5 倍。

工作流程之前和之后如图所示。

![](https://developer-blogs.nvidia.com/wp-content/uploads/2022/11/image3-6.png)


## NVIDIA Triton 的模型流水线编排优势
本节介绍 NIO 通过集成 NVIDIA Triton 实现的每项优势。

### GPU 加速预处理
NVIDIA Triton 使用 nvJPEG 和 NVIDIA DALI 在 GPU 上加速解码、调整大小和转置等预处理任务。这显着卸载了客户端 CPU 的计算工作负载并减少了预处理延迟。

### 无需修改客户端应用程序即可升级模型
通过将模型的预处理和后处理移至NVIDIA Triton，每次升级模型时，客户端无需进行任何修改。这从本质上加快了模型的推出，帮助它更快地投入生产。

### 使用单个 GPU 节点减少网络数据传输开销
统一的预处理使输入的多个副本能够与多个后端识别模型共享。该过程在服务器端使用 GPU 共享内存，没有数据传输开销成本。

下图显示流程可以使用 NVIDIA Triton 业务逻辑脚本功能连接多达九个模型。

![](https://developer-blogs.nvidia.com/wp-content/uploads/2022/11/image2-7.png)

对于 2K 分辨率的输入图像，每帧的大小为 1920 x 1080 x 3 x 8 = 47 Mb。假设全帧率为 60 fps，则每秒输入的数据量为 1920 x 1080 x 3 x 8 x 60 = 2847 Mb。在之前的工作流程中，每张图片都通过网络依次发送给九个模型。每秒传输的数据为 1920 x 1080 x 3 x 8 x 60 x 9 = 25 Gb = 3 GB。

在新的工作流程中，九个模型使用 NVIDIA Triton 业务逻辑脚本进行编排。这意味着模型可以访问 GPU 共享内存中的图像，而不必通过网络发送图像。假设 160 Gb 的 PCIe 带宽 = 每秒 20 GB，如果通过 PCIe 传输数据，理论上每秒生成的数据可以节省 150 毫秒的数据传输时间。

假设可用带宽为 16 Gb = 2 GB/秒，如果通过网络传输数据，理论上每秒生成的数据可以节省 1,500 毫秒的数据传输时间。所有这些都会加快工作流程。


### 使用图像压缩节省网络传输
为了准确的模型预测，在之前的工作流程中，输入图像必须是1920 x 1080 x 3 x 8字节，并且必须通过网络传输。引入服务器端预处理后，可以在允许的精度损失范围内将原始图像更改为压缩的三通道 720 像素图像（1280 x 720 x 3）。

因此，只需几百 KB 即可传输压缩图像的字节，并在服务器上以最小的精度损失将大小调整为 1920 x 1080 x 3 x 8 字节。这导致额外的网络传输节省，加快了工作流程。

### 易于集成到 NADP 推理平台中
NIO 当前基于 NVIDIA Triton 的推理平台是其自动驾驶开发平台 (NADP) 的关键组件，用于其自动驾驶解决方案。

由于 NIO 平台是基于 Kubernetes (K8s) 构建的，因此 NVIDIA Triton 必须与 Kubernetes 很好地集成。工作流程的组件以 NVIDIA Triton 周围的 K8s CRD（本机和自定义）的形式实现。

![](https://developer-blogs.nvidia.com/wp-content/uploads/2022/11/image4-5.png)

### 持续集成/持续交付 (CI/CD)
Argo 是用于编排 Kubernetes 中工作流的引擎。它通过 CI/CD 帮助所有涉及开发、量化、访问、云部署、压力测试和启动的组件。 NVIDIA Triton 通过在加载模型时触发工作流中的下一步来帮助 CI/CD。

此外，使用 NVIDIA Triton Docker 容器有助于在开发、测试和部署环境中实现一致的功能。

将 Jupyter 环境无缝集成到 NVIDIA Triton 图像中。 Jupyter 提供了一个方便的调试开发环境，以应对需要在线调试或离线复现的复杂问题。

### 使用 Istio 易于部署
NVIDIA Triton 原生支持 gRPC 协议以与应用程序通信。然而，由于 Kubernetes 原生服务无法为 gRPC 提供有效的请求级负载均衡，NVIDIA Triton 与 Istio 服务网格集成。 Istio 用于负载均衡到 NVIDIA Triton 推理服务器的流量，并通过 NVIDIA Triton 的活跃度/就绪度探测器监控服务的健康状况。

### 易于使用 Apollo 配置管理
Apollo 配置中心用于基于模型名称的服务发现。用户可以在不知道模型部署的具体域名的情况下访问模型。结合NVIDIA Triton模型库，用户可以直接触发模型的部署。

### Prometheus 和 Grafana 的指标
NVIDIA Triton 提供了一套完整的基于模型维度的模型服务指标。例如，NVIDIA Triton 可以区分推理请求排队时间和 GPU 计算时间，无需进入调试模式即可对在线模型服务性能进行细粒度诊断和分析。

由于NVIDIA Triton支持云原生主流Prometheus/Grafana，用户可以轻松配置仪表板和各个维度的告警，为服务高可用性提供指标支持。


要点
NIO 的优化工作流程集成了 NVIDIA Triton 推理服务器，使某些核心管道的延迟减少了 6 倍。 这将整体吞吐量提高了多达 5 倍。

通过使用 NVIDIA Triton 流水线编排功能将预处理逻辑转移到 GPU，NIO 实现了：

* 更快的图像处理
* 释放的 CPU 容量
* 减少网络传输开销
* 更高的推理吞吐量
NIO 使用 NVIDIA Triton 推理服务器实现了 AI 推理工作流加速。 NVIDIA Triton 也很容易集成到一个强大的基于 Kubernetes 的可扩展解决方案中。

























